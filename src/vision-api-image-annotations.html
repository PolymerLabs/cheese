<!--
@license
Copyright (c) 2017 The Polymer Project Authors. All rights reserved.
This code may only be used under the BSD style license found at http://polymer.github.io/LICENSE.txt
The compconste set of authors may be found at http://polymer.github.io/AUTHORS.txt
The compconste set of contributors may be found at http://polymer.github.io/CONTRIBUTORS.txt
Code distributed by Google as part of the polymer project is also
subject to an additional IP rights grant found at http://polymer.github.io/PATENTS.txt
-->

<link rel="import" href="../bower_components/polymer/polymer-element.html">



<script>
  class VisionApiImageAnnotations extends Polymer.Element {

    static get is() {
      return 'vision-api-image-annotations';
    }

    static get properties() {
      return {

        /**
         * The API key you created at https://cloud.google.com/console
         */
        apiKey: {
          type: String
        },

        /**
         * True when annotations are being loaded.
         */
        loading: {
          type: Boolean,
          readOnly: true,
          notify: true
        },

        /**
         * The string containing the image data URI.
         * Triggers the update of `lastAnnotations`.
         */
        imageDataUrl: {
          type: String
        },

        /**
         * Last value retrieved from the API for the given `imageDataUrl`.
         */
        lastAnnotations: {
          type: Object,
          readOnly: true,
          notify: true
        }
      }
    }

    static get observers() {
      return ['_loadAnnotations(imageDataUrl, apiKey)'];
    }

    constructor() {
      super();
      // Non-visual element.
      this.style.display = 'none';
    }

    reload() {
      this._loadAnnotations(this.imageDataUrl, this.apiKey);
    }

    _loadAnnotations(imageDataUrl, apiKey) {
      if (!imageDataUrl || !apiKey) {
        this._setLastAnnotations(null);
        this._setLoading(false);
        return;
      }
      const request = new XMLHttpRequest();
      request.open('POST', 'https://vision.googleapis.com/v1/images:annotate?key=' + apiKey, true);
      // Skip setting Content-Type to avoid OPTIONS request, we know this API handles JSON.
      request.onload = () => {
        let annotations = null;
        if (request.status === 304 || request.status === 0 ||
          request.status >= 200 && request.status < 300) {
          const json = JSON.parse(request.response || request.responseText);
          annotations = json.responses ? json.responses[0] : null;
        }
        this._computeFaces(annotations);
        this._setLastAnnotations(annotations);
        this._setLoading(false);
      };
      request.onerror = () => {
        this._setLastAnnotations(null);
        this._setLoading(false);
      };

      const rawImageData = imageDataUrl.substring(imageDataUrl.indexOf(',') + 1);
      const requestBody = {
        requests: [{
          image: {
            content: rawImageData
          },
          // Consider exposing these features.
          features: [{
            type: 'FACE_DETECTION'
          }, {
            type: 'LABEL_DETECTION'
          }]
        }]
      };
      this._setLoading(true);
      request.send(JSON.stringify(requestBody));
    }

    /**
     * Enrich annotations with face emotions and bounds data.
     */
    _computeFaces(annotations) {
      // No faces detected.
      if (!annotations || !annotations.faceAnnotations) return;
      annotations.faceAnnotations.forEach(face => {
        Object.assign(face, {
          emotions: this._computeFaceEmotions(face),
          bounds: this._computeFaceBounds(face)
        });
      });
    }

    _computeFaceEmotions(face) {
      const decreasingLikelihoods = ['VERY_LIKELY', 'LIKELY', 'POSSIBLE'];
      const sorted = [];
      for (let i = 0; i < decreasingLikelihoods.length; ++i) {
        const currentLikelihood = decreasingLikelihoods[i];
        if (face.joyLikelihood === currentLikelihood) {
          sorted.push('joy');
        }
        if (face.surpriseLikelihood === currentLikelihood) {
          sorted.push('surprise');
        }
        if (face.sorrowLikelihood === currentLikelihood) {
          sorted.push('sorrow');
        }
        if (face.angerLikelihood === currentLikelihood) {
          sorted.push('anger');
        }
      }
      if (!sorted.length) sorted.push('normal');

      return sorted;
    }

    _computeFaceBounds(face) {
      const faceBounds = this._computeBounds(face.boundingPoly.vertices, [0, 1, 2, 3]);
      const innerFaceBounds = this._computeBounds(face.fdBoundingPoly.vertices, [0, 1, 2, 3]);
      const landmarks = this._computeLandmarks(face);
      const rotation = {
        x: face.tiltAngle,
        y: face.panAngle,
        z: face.rollAngle
      };
      const bounds = {};

      bounds.face = Object.assign({}, faceBounds);
      // Make it square.
      if (bounds.face.width >= bounds.face.height) {
        bounds.face.top += bounds.face.height / 2 - bounds.face.width / 2;
        bounds.face.height = bounds.face.width;
      } else {
        bounds.face.left += bounds.face.width / 2 - bounds.face.height / 2;
        bounds.face.width = bounds.face.height;
      }
      bounds.face.rotation = rotation;

      // belowFace
      bounds.belowFace = Object.assign({}, faceBounds);
      bounds.belowFace.top += bounds.belowFace.height;
      bounds.belowFace.anchorPoint = {
        x: 0.5,
        y: 0
      };

      // aboveFace
      bounds.aboveFace = Object.assign({}, faceBounds);
      bounds.aboveFace.top -= bounds.aboveFace.height;
      bounds.aboveFace.anchorPoint = {
        x: 0.5,
        y: 1
      };

      // forehead
      bounds.forehead = Object.assign({}, innerFaceBounds);
      bounds.forehead.top -= bounds.forehead.height;
      bounds.forehead.anchorPoint = {
        x: 0.5,
        y: 1.5
      };
      bounds.forehead.rotation = rotation;

      // leftEye
      bounds.leftEye = this._computeBounds(landmarks, [
        'LEFT_EYE_PUPIL'
      ]);
      bounds.leftEye.width = bounds.leftEye.height = faceBounds.width * 0.3;
      bounds.leftEye.left -= bounds.leftEye.width / 2;
      bounds.leftEye.top -= bounds.leftEye.width / 2;
      bounds.leftEye.rotation = rotation;

      // rightEye
      bounds.rightEye = this._computeBounds(landmarks, [
        'RIGHT_EYE_PUPIL'
      ]);
      bounds.rightEye.width = bounds.rightEye.height = faceBounds.width * 0.3;
      bounds.rightEye.left -= bounds.rightEye.width / 2;
      bounds.rightEye.top -= bounds.rightEye.height / 2;
      bounds.rightEye.rotation = rotation;

      // eyes
      bounds.eyes = this._computeBounds(landmarks, [
        'MIDPOINT_BETWEEN_EYES'
      ]);
      bounds.eyes.width = bounds.eyes.height = faceBounds.width * 0.7;
      bounds.eyes.left -= bounds.eyes.width / 2;
      bounds.eyes.top -= bounds.eyes.height / 2;
      bounds.eyes.rotation = rotation;

      // nose
      bounds.nose = this._computeBounds(landmarks, [
        'MIDPOINT_BETWEEN_EYES',
        'NOSE_TIP',
        'NOSE_BOTTOM_RIGHT',
        'NOSE_BOTTOM_LEFT',
        'NOSE_BOTTOM_CENTER'
      ]);
      bounds.nose.left += bounds.nose.width / 2 - bounds.nose.height / 2;
      bounds.nose.width = bounds.nose.height;
      bounds.nose.rotation = rotation;

      // mouth
      bounds.mouth = this._computeBounds(landmarks, [
        'MOUTH_CENTER'
      ]);
      bounds.mouth.width = bounds.mouth.height = innerFaceBounds.width * 0.5;
      bounds.mouth.left -= bounds.mouth.width / 2;
      bounds.mouth.top -= bounds.mouth.height / 2;
      bounds.mouth.rotation = rotation;

      return bounds;
    }

    _computeLandmarks(faceAnnotation) {
      return faceAnnotation.landmarks.reduce((res, lm) => {
        res[lm.type] = lm.position;
        return res;
      }, {});
    }

    _computeBounds(landmarks, keys) {
      const minMax = this._computeMinMax(landmarks, keys);
      const left = minMax.min.x;
      const top = minMax.min.y;
      const width = minMax.max.x - left;
      const height = minMax.max.y - top;
      return {
        top,
        left,
        width,
        height
      };
    }

    _computeMinMax(landmarks, keys) {
      return keys.reduce((res, key) => {
        const position = landmarks[key] || {};
        res.min.x = Math.min(position.x || 0, res.min.x);
        res.min.y = Math.min(position.y || 0, res.min.y);
        res.min.z = Math.min(position.z || 0, res.min.z);
        res.max.x = Math.max(position.x || 0, res.max.x);
        res.max.y = Math.max(position.y || 0, res.max.y);
        res.max.z = Math.max(position.z || 0, res.max.z);
        return res;
      }, {
        min: {
          x: Infinity,
          y: Infinity,
          z: Infinity
        },
        max: {
          x: -Infinity,
          y: -Infinity,
          z: -Infinity
        }
      });
    }

  }

  customElements.define(VisionApiImageAnnotations.is, VisionApiImageAnnotations);
</script>